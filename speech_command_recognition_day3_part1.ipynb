{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech command recognition - Day 3 Part 1\n",
    "## Model improvement - Data augmentation\n",
    "******\n",
    "Author: Duowei Tang \\\n",
    "Reference: This exercise is adopted from a Pytorch tutorial: https://pytorch.org/tutorials/intermediate/speech_command_classification_with_torchaudio_tutorial.html \\\n",
    "Pytorch ignite: https://pytorch-ignite.ai/ \\\n",
    "The Aachen RIR dataset: https://www.iks.rwth-aachen.de/en/research/tools-downloads/databases/aachen-impulse-response-database/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchaudio.datasets import SPEECHCOMMANDS\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class lables\n",
    "*******\n",
    "In the code block below, it listed the selected command classes and all class labels that are commented out are considered as \"unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['forward', 'backward', 'up', 'down',\n",
    "          'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'zero',\n",
    "          'left', 'right', 'go', 'stop', 'yes', 'no', 'on', 'off', 'unknown']\n",
    "# The following dataset labels are considered unkonwn\n",
    "# unknown = ['bed', 'bird', 'cat', 'dog', 'follow', 'happy', 'house', 'learn', 'marvin',\n",
    "#            'sheila', 'visual', 'wow', 'tree']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the datasets\n",
    "*******\n",
    "Unlike the previous day where we first store the extracted MFCC features to the disk and load the pre-computed features during training. In this exercise, we will extract the features on-the-fly during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEECH_DATA_ROOT = \"/Users/invincibleo/Leo/Projects/Datasets/SpeechCommands\"\n",
    "# Load the speech command dataset from pytorch dataset\n",
    "class SubsetSC(SPEECHCOMMANDS):\n",
    "    def __init__(self, subset: str = None):\n",
    "        super().__init__(os.path.dirname(SPEECH_DATA_ROOT), download=True)\n",
    "\n",
    "        def load_list(filename):\n",
    "            filepath = os.path.join(self._path, filename)\n",
    "            with open(filepath) as fileobj:\n",
    "                return [os.path.normpath(os.path.join(self._path, line.strip())) for line in fileobj]\n",
    "\n",
    "        if subset == \"validation\":\n",
    "            self._walker = load_list(\"validation_list.txt\")\n",
    "        elif subset == \"testing\":\n",
    "            self._walker = load_list(\"testing_list.txt\")\n",
    "        elif subset == \"training\":\n",
    "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
    "            excludes = set(excludes)\n",
    "            self._walker = [w for w in self._walker if w not in excludes]\n",
    "\n",
    "# Create the paritions and features will be extracted during training\n",
    "train_set = SubsetSC(\"training\")\n",
    "valid_set = SubsetSC(\"validation\")\n",
    "test_set = SubsetSC(\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_index(word):\n",
    "    if word in labels:\n",
    "        return torch.tensor(labels.index(word))\n",
    "    else:\n",
    "        return torch.tensor(labels.index(\"unknown\"))\n",
    "\n",
    "def index_to_label(index):\n",
    "    # Return the word corresponding to the index in labels\n",
    "    # This is the inverse of label_to_index\n",
    "    return labels[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation examples\n",
    "*******\n",
    "In this section, we will try out several speech data augmentation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 16000\n",
    "output_root = \"dataAugOut/\"\n",
    "\n",
    "def add_exist_noise(waveform):\n",
    "    # Apply existing noise\n",
    "    noise_files = glob.glob(os.path.join(SPEECH_DATA_ROOT, \"speech_commands_v0.02\", \"_background_noise_\", \"*.wav\"))\n",
    "    noise_file = noise_files[torch.randint(0, len(noise_files), (1,)).item()]\n",
    "    noise_waveform, _ = torchaudio.load(noise_file)\n",
    "    # Make waveform and noise the same length by padding with zeros\n",
    "    if noise_waveform.size(-1) < waveform.size(-1):\n",
    "        noise_waveform = F.pad(noise_waveform, (0, waveform.size(-1) - noise_waveform.size(-1)))\n",
    "    elif noise_waveform.size(-1) >= waveform.size(-1):\n",
    "        # randomly crop noise\n",
    "        max_offset = noise_waveform.size(-1) - waveform.size(-1)\n",
    "        offset = torch.randint(0, max_offset, (1,))\n",
    "        noise_waveform = noise_waveform[..., offset:offset+waveform.size(-1)]\n",
    "    waveform = torchaudio.transforms.AddNoise()(waveform, noise_waveform, snr=torch.randint(-5, 10, (1,)))\n",
    "    return waveform\n",
    "\n",
    "def time_shift(waveform):\n",
    "    # Apply time shift\n",
    "    shift_amount = int(sample_rate*0.3*torch.randint(-1, 1, (1,)).item())\n",
    "    # Apply random time shift to waveform and zero pad at the beginning or at the end\n",
    "    if shift_amount > 0:\n",
    "        waveform = waveform[..., :-shift_amount]\n",
    "        waveform = F.pad(waveform, (shift_amount, 0))\n",
    "    else:\n",
    "        waveform = waveform[..., -shift_amount:]\n",
    "        waveform = F.pad(waveform, (0, -shift_amount))\n",
    "    return waveform\n",
    "\n",
    "def perturbate_speed(waveform):\n",
    "    waveform_aug = torchaudio.transforms.SpeedPerturbation(orig_freq=sample_rate, factors=[0.9, 1.1, 1.0, 1.0])(waveform)[0]\n",
    "    if waveform_aug.size(-1) < waveform.size(-1):\n",
    "        waveform_aug = F.pad(waveform_aug, (0, waveform.size(-1) - waveform.size(-1)))\n",
    "    else:\n",
    "        length_diff = waveform_aug.size(-1) - waveform.size(-1)\n",
    "        waveform_aug = waveform_aug[..., length_diff//2:length_diff//2+waveform.size(-1)]\n",
    "    return waveform_aug\n",
    "\n",
    "def adjust_volume(waveform):\n",
    "    # Apply volume adjustment\n",
    "    waveform = torchaudio.transforms.Vol(gain=torch.randint(low=-10, high=10, size=(1,)), gain_type='db')(waveform)\n",
    "    return waveform\n",
    "\n",
    "def add_white_noise(waveform):\n",
    "    # Apply white noise\n",
    "    waveform = torchaudio.transforms.AddNoise()(waveform, torch.randn_like(waveform), snr=torch.randint(low=-5, high=10, size=(1,)))\n",
    "    return waveform\n",
    "\n",
    "def time_mask(waveform):\n",
    "    # Apply time masking\n",
    "    waveform = torchaudio.transforms.TimeMasking(time_mask_param=int(0.1*sample_rate), p=1.0)(waveform)\n",
    "    return waveform\n",
    "\n",
    "def augment_rir(waveform):\n",
    "    # Apply room impulse response\n",
    "    rir_files = glob.glob(os.path.join(\"AIR_wav_files\", \"*.wav\"))\n",
    "    rir_file = rir_files[torch.randint(0, len(rir_files), (1,)).item()]\n",
    "    rir_waveform, _ = torchaudio.load(rir_file)\n",
    "    waveform_aug = torchaudio.functional.fftconvolve(waveform, rir_waveform)\n",
    "    waveform_aug = waveform_aug[..., :sample_rate]\n",
    "    return waveform_aug       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data augmentation functions - Add existing noise\n",
    "for i, (waveform, sample_rate, label, speaker_id, utterance_number) in enumerate(train_set):\n",
    "    if i == 10:\n",
    "        break\n",
    "    waveform_aug = add_exist_noise(waveform)\n",
    "    # save the augmented waveform and original waveform\n",
    "    os.makedirs(os.path.join(output_root, \"addExistNoise\"), exist_ok=True)\n",
    "    torchaudio.save(os.path.join(output_root, \"addExistNoise\", f\"{speaker_id}_{utterance_number}_{label}_aug.wav\"), waveform_aug, sample_rate)\n",
    "    torchaudio.save(os.path.join(output_root, \"addExistNoise\", f\"{speaker_id}_{utterance_number}_{label}_org.wav\"), waveform, sample_rate)\n",
    "\n",
    "    if i == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(waveform.t().numpy())\n",
    "        plt.title(\"Original waveform\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(waveform_aug.t().numpy())\n",
    "        plt.title(\"Augmented waveform\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data augmentation functions - Time shift\n",
    "for i, (waveform, sample_rate, label, speaker_id, utterance_number) in enumerate(train_set):\n",
    "    if i == 10:\n",
    "        break\n",
    "    waveform_aug = time_shift(waveform)\n",
    "    # save the augmented waveform and original waveform\n",
    "    os.makedirs(os.path.join(output_root, \"timeShift\"), exist_ok=True)\n",
    "    torchaudio.save(os.path.join(output_root, \"timeShift\", f\"{speaker_id}_{utterance_number}_{label}_aug.wav\"), waveform_aug, sample_rate)\n",
    "    torchaudio.save(os.path.join(output_root, \"timeShift\", f\"{speaker_id}_{utterance_number}_{label}_org.wav\"), waveform, sample_rate)\n",
    "\n",
    "    if i == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(waveform.t().numpy())\n",
    "        plt.title(\"Original waveform\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(waveform_aug.t().numpy())\n",
    "        plt.title(\"Augmented waveform\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data augmentation functions - Perturbate speed\n",
    "for i, (waveform, sample_rate, label, speaker_id, utterance_number) in enumerate(train_set):\n",
    "    if i == 10:\n",
    "        break\n",
    "    waveform_aug = perturbate_speed(waveform)\n",
    "    # save the augmented waveform and original waveform\n",
    "    os.makedirs(os.path.join(output_root, \"perturbateSpeed\"), exist_ok=True)\n",
    "    torchaudio.save(os.path.join(output_root, \"perturbateSpeed\", f\"{speaker_id}_{utterance_number}_{label}_aug.wav\"), waveform_aug, sample_rate)\n",
    "    torchaudio.save(os.path.join(output_root, \"perturbateSpeed\", f\"{speaker_id}_{utterance_number}_{label}_org.wav\"), waveform, sample_rate)\n",
    "\n",
    "    if i == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(waveform.t().numpy())\n",
    "        plt.title(\"Original waveform\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(waveform_aug.t().numpy())\n",
    "        plt.title(\"Augmented waveform\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data augmentation functions - Adjust volume\n",
    "for i, (waveform, sample_rate, label, speaker_id, utterance_number) in enumerate(train_set):\n",
    "    if i == 10:\n",
    "        break\n",
    "    waveform_aug = adjust_volume(waveform)\n",
    "    # save the augmented waveform and original waveform\n",
    "    os.makedirs(os.path.join(output_root, \"adjustVolume\"), exist_ok=True)\n",
    "    torchaudio.save(os.path.join(output_root, \"adjustVolume\", f\"{speaker_id}_{utterance_number}_{label}_aug.wav\"), waveform_aug, sample_rate)\n",
    "    torchaudio.save(os.path.join(output_root, \"adjustVolume\", f\"{speaker_id}_{utterance_number}_{label}_org.wav\"), waveform, sample_rate)\n",
    "\n",
    "    if i == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(waveform.t().numpy())\n",
    "        plt.title(\"Original waveform\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(waveform_aug.t().numpy())\n",
    "        plt.title(\"Augmented waveform\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data augmentation functions - Add white noise\n",
    "for i, (waveform, sample_rate, label, speaker_id, utterance_number) in enumerate(train_set):\n",
    "    if i == 10:\n",
    "        break\n",
    "    waveform_aug = add_white_noise(waveform)\n",
    "    # save the augmented waveform and original waveform\n",
    "    os.makedirs(os.path.join(output_root, \"addWhiteNoise\"), exist_ok=True)\n",
    "    torchaudio.save(os.path.join(output_root, \"addWhiteNoise\", f\"{speaker_id}_{utterance_number}_{label}_aug.wav\"), waveform_aug, sample_rate)\n",
    "    torchaudio.save(os.path.join(output_root, \"addWhiteNoise\", f\"{speaker_id}_{utterance_number}_{label}_org.wav\"), waveform, sample_rate)\n",
    "\n",
    "    if i == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(waveform.t().numpy())\n",
    "        plt.title(\"Original waveform\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(waveform_aug.t().numpy())\n",
    "        plt.title(\"Augmented waveform\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data augmentation functions - Time mask\n",
    "for i, (waveform, sample_rate, label, speaker_id, utterance_number) in enumerate(train_set):\n",
    "    if i == 10:\n",
    "        break\n",
    "    waveform_aug = time_mask(waveform)\n",
    "    # save the augmented waveform and original waveform\n",
    "    os.makedirs(os.path.join(output_root, \"timeMask\"), exist_ok=True)\n",
    "    torchaudio.save(os.path.join(output_root, \"timeMask\", f\"{speaker_id}_{utterance_number}_{label}_aug.wav\"), waveform_aug, sample_rate)\n",
    "    torchaudio.save(os.path.join(output_root, \"timeMask\", f\"{speaker_id}_{utterance_number}_{label}_org.wav\"), waveform, sample_rate)\n",
    "\n",
    "    if i == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(waveform.t().numpy())\n",
    "        plt.title(\"Original waveform\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(waveform_aug.t().numpy())\n",
    "        plt.title(\"Augmented waveform\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data augmentation functions - Augment RIR\n",
    "for i, (waveform, sample_rate, label, speaker_id, utterance_number) in enumerate(train_set):\n",
    "    if i == 10:\n",
    "        break\n",
    "    waveform_aug = augment_rir(waveform)\n",
    "    # save the augmented waveform and original waveform\n",
    "    os.makedirs(os.path.join(output_root, \"augmentRIR\"), exist_ok=True)\n",
    "    torchaudio.save(os.path.join(output_root, \"augmentRIR\", f\"{speaker_id}_{utterance_number}_{label}_aug.wav\"), waveform_aug, sample_rate)\n",
    "    torchaudio.save(os.path.join(output_root, \"augmentRIR\", f\"{speaker_id}_{utterance_number}_{label}_org.wav\"), waveform, sample_rate)\n",
    "\n",
    "    if i == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(waveform.t().numpy())\n",
    "        plt.title(\"Original waveform\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(waveform_aug.t().numpy())\n",
    "        plt.title(\"Augmented waveform\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sounds4th",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
